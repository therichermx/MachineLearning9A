{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "41d0760b-de64-4caf-8a62-c12fee998c7a",
      "metadata": {
        "id": "41d0760b-de64-4caf-8a62-c12fee998c7a"
      },
      "source": [
        "# K - Nearest Neighbor Algorithm (KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a415fa29-2c78-4a46-9ba8-7e6bafcdcbd0",
      "metadata": {
        "id": "a415fa29-2c78-4a46-9ba8-7e6bafcdcbd0"
      },
      "source": [
        "Nearest Neighbor means that we can analize observations that are the most similar to others in a dataset, and classify them based on the values that are the closest point\n",
        "\n",
        "K is what allows the user to select the size / number of neighbors that we take into consideration per point.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a05240a-2901-4364-8bfd-893e720e6d16",
      "metadata": {
        "id": "1a05240a-2901-4364-8bfd-893e720e6d16"
      },
      "source": [
        "### Pseudocode"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9ce1b8b-1af2-4ee7-bdf6-9b8cac53fd3d",
      "metadata": {
        "id": "c9ce1b8b-1af2-4ee7-bdf6-9b8cac53fd3d"
      },
      "source": [
        "Function euclidean_distance:\n",
        "- calculate the Euclidean distance between two vectors\n",
        "- Return square root of distance\n",
        "\n",
        "Function get_neighbors:\n",
        "- Initialize an empty list distances\n",
        "- For each row in train:\n",
        "    * Calculate Euclidean distance between test_row and the current row\n",
        "    * Append (current row, distance) to distances list\n",
        "- Sort distances based on distance in ascending order\n",
        "- Return the first num_neighbors rows from distances\n",
        "\n",
        "Function predict_classification:\n",
        "- Get the K nearest neighbors\n",
        "- Extract output values from neighbors\n",
        "- Return the mode (most frequent value) of the output values\n",
        "\n",
        "Test distance function:\n",
        "- Initialize the dataset with sample data\n",
        "- Call predict_classification with the dataset, the first row of the dataset, and 3 as arguments, store the result in prediction\n",
        "- Print expected and predicted class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ed0c85-2ad9-4c5b-8c4f-78973b46255e",
      "metadata": {
        "id": "d5ed0c85-2ad9-4c5b-8c4f-78973b46255e"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfc391d0-bb52-4f34-aaa6-bb8fc78d6eca",
      "metadata": {
        "id": "cfc391d0-bb52-4f34-aaa6-bb8fc78d6eca"
      },
      "outputs": [],
      "source": [
        "# Importing\n",
        "import csv\n",
        "from math import sqrt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d31a80b-a249-4795-8bac-d92c933819f0",
      "metadata": {
        "id": "6d31a80b-a249-4795-8bac-d92c933819f0"
      },
      "outputs": [],
      "source": [
        "def load_csv(filename):\n",
        "    dataset = []\n",
        "    columns_to_remove = [0,1,2,3,4]  # Indices of columns to remove (0-based indexing)\n",
        "\n",
        "    with open(filename, 'r', encoding='cp437') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "        for row in csv_reader:\n",
        "            if not row:\n",
        "                continue\n",
        "\n",
        "            # Remove specified columns\n",
        "            modified_row = [row[i] for i in range(len(row)) if i not in columns_to_remove]\n",
        "            dataset.append(modified_row)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        dataset = dataset[1:]  # Exclude the first row\n",
        "    else:\n",
        "        print(\"Dataset is empty or does not contain any rows.\")\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad945202-767b-4350-8ba7-69bb075d5c9d",
      "metadata": {
        "id": "ad945202-767b-4350-8ba7-69bb075d5c9d"
      },
      "source": [
        "Here we take a column for the current row, then we remove any whitespace using the function strip(), and convert the string to float.\n",
        "\n",
        "We need to do this because we need to calculate the distances between datapoints, so by converting strings of numbers to actual numerical values, we can actually work with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "276de9eb-487d-49b9-856d-e171bbf91887",
      "metadata": {
        "id": "276de9eb-487d-49b9-856d-e171bbf91887"
      },
      "outputs": [],
      "source": [
        "def str_column_to_float(dataset, column):\n",
        "    for row in dataset:\n",
        "        try:\n",
        "            row[column] = float(row[column].strip())\n",
        "        except ValueError:\n",
        "            row[column] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec3dfea-e52e-4f93-82a0-d22fd976e20d",
      "metadata": {
        "id": "8ec3dfea-e52e-4f93-82a0-d22fd976e20d"
      },
      "source": [
        "We create a \"dictionary\" called lookup where we iterate through the unique class values, assign an integer label to each unique value, and print them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c6b27a-c8fd-4cbe-94e3-9162a2215d6d",
      "metadata": {
        "id": "95c6b27a-c8fd-4cbe-94e3-9162a2215d6d"
      },
      "outputs": [],
      "source": [
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "    class_values = [row[column] for row in dataset]\n",
        "    unique = set(class_values) # Converts the list of class values to a set to obtain unique class values.\n",
        "    lookup = dict()\n",
        "    for i, value in enumerate(unique):\n",
        "        lookup[value] = i\n",
        "        print('[%s] => %d' % (value, i))\n",
        "    for row in dataset:\n",
        "        row[column] = lookup[row[column]]\n",
        "    return lookup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a273f0-9688-4035-926d-d6d2b4e5b13c",
      "metadata": {
        "id": "e8a273f0-9688-4035-926d-d6d2b4e5b13c"
      },
      "source": [
        "We determine the range of values for each column in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09479d5d-1d96-40d3-b059-291764e3c9d7",
      "metadata": {
        "id": "09479d5d-1d96-40d3-b059-291764e3c9d7"
      },
      "outputs": [],
      "source": [
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "    minmax = list() #list to store the minmax values for each column.\n",
        "    for i in range(len(dataset[0])): # Iterates through each column\n",
        "        col_values = [row[i] for row in dataset] # Extracts the values from the current column\n",
        "        value_min = min(col_values)\n",
        "        value_max = max(col_values)\n",
        "        minmax.append([value_min, value_max])\n",
        "    return minmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8846a63-17bd-48cc-8d6a-ea9ebef95fac",
      "metadata": {
        "id": "f8846a63-17bd-48cc-8d6a-ea9ebef95fac"
      },
      "outputs": [],
      "source": [
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "    for row in dataset:\n",
        "        for i in range(len(row)): # Iterates through each row in the dataset and then through each column within that row.\n",
        "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f31024d-d2b2-4a0a-928b-795d208ecf20",
      "metadata": {
        "id": "1f31024d-d2b2-4a0a-928b-795d208ecf20"
      },
      "source": [
        "The first step for KNN is to calculate the distance between two rows in a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adc8393b-5a3c-4001-9649-db9985388625",
      "metadata": {
        "id": "adc8393b-5a3c-4001-9649-db9985388625"
      },
      "outputs": [],
      "source": [
        "# Calculate the Euclidean distance between two vectors\n",
        "def euclidean_distance(row1, row2):\n",
        "    distance = 0.0\n",
        "    for i in range(len(row1) - 1):\n",
        "        distance += (row1[i] - row2[i]) ** 2\n",
        "    return sqrt(distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7286a327-c232-4b5f-a5f7-71f72f32a11d",
      "metadata": {
        "id": "7286a327-c232-4b5f-a5f7-71f72f32a11d"
      },
      "source": [
        "After that, we need to calculate the distance between each observation in the dataset to the new piece of data. Then classify all observations in the training dataset by their distance to the new data.\n",
        "\n",
        "We select the top *k* to return as the most similar neighbors.\n",
        "\n",
        "Here, lambda defines an anonymous function that takes a single tuple and returns the second element of the tuple, *tup[1]*. The data point and its distance from the test_row are added as a tuple to the distances list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cb69e71-aa85-4741-9c0d-709684668233",
      "metadata": {
        "id": "8cb69e71-aa85-4741-9c0d-709684668233"
      },
      "outputs": [],
      "source": [
        "# Locate the most similar neighbors\n",
        "def get_neighbors(train, test_row, num_neighbors):\n",
        "    distances = list() # Initialize an Empty List for Distances\n",
        "    for train_row in train:\n",
        "        dist = euclidean_distance(test_row, train_row)\n",
        "        distances.append((train_row, dist))\n",
        "    distances.sort(key=lambda tup: tup[1])\n",
        "    neighbors = list()\n",
        "    for i in range(num_neighbors):\n",
        "        neighbors.append(distances[i][0])\n",
        "    return neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ceb3870-de00-4c3f-9807-89bcefae963e",
      "metadata": {
        "id": "4ceb3870-de00-4c3f-9807-89bcefae963e"
      },
      "source": [
        "After identifying the classes of the K nearest neighbors for a given data point, we have a list of output values representing the classes of these neighbors.\n",
        "\n",
        "The max() function is then applied to this list of output values to return the maximum value in that list (in this case, the classes).\n",
        "\n",
        "**train:** The training dataset containing labeled data points.\n",
        "\n",
        "**test_row:** The data point for the prediction.\n",
        "\n",
        "**num_neighbors:** The number of nearest neighbors to consider for the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57ea3a5-b826-4032-8572-fa557c8c24d6",
      "metadata": {
        "id": "e57ea3a5-b826-4032-8572-fa557c8c24d6"
      },
      "outputs": [],
      "source": [
        "# Make a prediction with neighbors\n",
        "def predict_classification(train, test_row, num_neighbors):\n",
        "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
        "    output_values = [row[-1] for row in neighbors]\n",
        "    prediction = max(set(output_values), key=output_values.count) # finds the most common output label\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2167a648-82da-4710-aca0-bd153d1bca8c",
      "metadata": {
        "id": "2167a648-82da-4710-aca0-bd153d1bca8c"
      },
      "source": [
        "Main Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63adc481-6bd6-419a-992a-0b9d2c7a2045",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63adc481-6bd6-419a-992a-0b9d2c7a2045",
        "outputId": "8174b37a-6fa5-48a1-a422-76eec576cb76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Medio] => 0\n",
            "[Bajo] => 1\n",
            "[Muy bajo] => 2\n",
            "[Muy alto] => 3\n",
            "[Alto] => 4\n",
            "Data=[5.7, 2.9, 4.2, 1.3], Predicted: 0\n"
          ]
        }
      ],
      "source": [
        "filename = './datasets/Indicadores_municipales.csv'\n",
        "dataset = load_csv(filename)\n",
        "\n",
        "for i in range(len(dataset[0])-1): # iterate through each column excluding the target variable\n",
        "    str_column_to_float(dataset, i) # convert string to float.\n",
        "\n",
        "# Convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# Define Neighbors\n",
        "num_neighbors = 5\n",
        "# Define a new observation\n",
        "row = [5.7, 2.9, 4.2, 1.3]\n",
        "\n",
        "# Predict the label\n",
        "label = predict_classification(dataset, row, num_neighbors)\n",
        "print('Data=%s, Predicted: %s' % (row, label))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3d12b1f-f026-432c-98c3-9bbe9198ae2f",
      "metadata": {
        "id": "c3d12b1f-f026-432c-98c3-9bbe9198ae2f"
      },
      "source": [
        "### Loss and Optimization Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af5e12ec-a70c-4987-b8fe-5f7ae1ab40c6",
      "metadata": {
        "id": "af5e12ec-a70c-4987-b8fe-5f7ae1ab40c6"
      },
      "source": [
        "A loss function is used to measure the accuracy of a model’s predictions. It calculates the difference between the predicted output and the actual output for each training sample.\n",
        "\n",
        "KNN does not inherently involve a loss function in the same way as supervised learning models. No function is fitted to the data, as such, no optimization is performed\n",
        "\n",
        "However we can still calculate the accuracy of our predictions through cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b6bc36f-084b-4598-84b8-b0b2506eecf9",
      "metadata": {
        "id": "9b6bc36f-084b-4598-84b8-b0b2506eecf9"
      },
      "outputs": [],
      "source": [
        "# Importing\n",
        "from random import seed\n",
        "from random import randrange"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f27c66-1dda-4c74-9bff-5e59e4247801",
      "metadata": {
        "id": "35f27c66-1dda-4c74-9bff-5e59e4247801"
      },
      "source": [
        "\"Folds\" refers to the subdivisions into which a dataset is divided for evaluating\n",
        "\n",
        "For each fold, we iterate n times. Within each iteration, we create a new fold and populate it with fold_size samples randomly selected from the dataset copy.\n",
        "\n",
        "We use randrange to select a random index from dataset_copy, and add it to the fold. We then remove it from dataset_copy to avoid duplication.\n",
        "\n",
        "Finally, the fold is added to dataset_split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbcd7167-f7eb-4cb8-945b-879a269ce280",
      "metadata": {
        "id": "dbcd7167-f7eb-4cb8-945b-879a269ce280"
      },
      "outputs": [],
      "source": [
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "    dataset_split = list()\n",
        "    dataset_copy = list(dataset)\n",
        "    fold_size = int(len(dataset) / n_folds) # Calculates the size of each fold\n",
        "    for _ in range(n_folds):\n",
        "        fold = list()\n",
        "        while len(fold) < fold_size:\n",
        "            index = randrange(len(dataset_copy)) # select a random index from dataset_copy\n",
        "            fold.append(dataset_copy.pop(index)) # remove from dataset_copy to avoid duplication.\n",
        "        dataset_split.append(fold)\n",
        "    return dataset_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f28683b8-b61a-444a-ac31-6ec3d5511f0a",
      "metadata": {
        "id": "f28683b8-b61a-444a-ac31-6ec3d5511f0a"
      },
      "source": [
        "Predict the labels for the test dataset using the KNN algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffa76a3-ece1-46ca-880e-7799be3ca2ce",
      "metadata": {
        "id": "cffa76a3-ece1-46ca-880e-7799be3ca2ce"
      },
      "outputs": [],
      "source": [
        "# kNN Algorithm\n",
        "def k_nearest_neighbors(train, test, num_neighbors):\n",
        "    predictions = list()\n",
        "    for row in test:\n",
        "        output = predict_classification(train, row, num_neighbors)\n",
        "        predictions.append(output)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "569e1e5d-4fcf-40cc-bee0-89ab0e29bdba",
      "metadata": {
        "id": "569e1e5d-4fcf-40cc-bee0-89ab0e29bdba"
      },
      "source": [
        "Comparing the predicted labels with the actual labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae6d171-273d-463f-ae25-7eae67e3a66f",
      "metadata": {
        "id": "bae6d171-273d-463f-ae25-7eae67e3a66f"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "    correct = 0 # keep track of correct predictions\n",
        "    for i in range(len(actual)):\n",
        "        if actual[i] == predicted[i]: #  check if the actual label matches the predicted label\n",
        "            correct += 1\n",
        "    return correct / float(len(actual)) * 100.0 # get percentage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f41ff3a-b314-406b-94e5-2f7db74bfcab",
      "metadata": {
        "id": "4f41ff3a-b314-406b-94e5-2f7db74bfcab"
      },
      "source": [
        "Here we apply Cross-validation, which is when the dataset is randomly split up into 'k' groups. One of the groups is used as the test set and the rest are used as the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dba6ea44-1989-418c-aff0-c345900f02f6",
      "metadata": {
        "id": "dba6ea44-1989-418c-aff0-c345900f02f6"
      },
      "outputs": [],
      "source": [
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "    folds = cross_validation_split(dataset, n_folds)\n",
        "    scores = list()\n",
        "    for fold in folds:\n",
        "        train_set = list(folds) # create a training set by combining all folds except the current fold.\n",
        "        train_set.remove(fold)\n",
        "        train_set = sum(train_set, []) # separate the current fold as the test set.\n",
        "        test_set = list()\n",
        "        for row in fold: # preparing the test set by creating a copy of each row in the fold\n",
        "            row_copy = list(row)\n",
        "            test_set.append(row_copy) # Add copied row to the test_set\n",
        "            row_copy[-1] = None # remove the label from the row\n",
        "        predicted = algorithm(train_set, test_set, *args)\n",
        "        actual = [row[-1] for row in fold] # Extract the actual labels from the current fold.\n",
        "        accuracy = accuracy_metric(actual, predicted)\n",
        "        scores.append(accuracy)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0200d018-1f2e-4762-a5c5-4871e34f317c",
      "metadata": {
        "id": "0200d018-1f2e-4762-a5c5-4871e34f317c"
      },
      "source": [
        "KNN itself doesn't have an usual training phase with model parameters, but cross-validation helps in understanding how well the algorithm performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9453c3f-60fd-4b3a-8e97-c722abc0bd98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9453c3f-60fd-4b3a-8e97-c722abc0bd98",
        "outputId": "e34ae597-f4a7-41fb-b600-b7c4854daa7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Medio] => 0\n",
            "[Bajo] => 1\n",
            "[Muy bajo] => 2\n",
            "[Muy alto] => 3\n",
            "[Alto] => 4\n",
            "Scores: [23.625254582484725, 33.604887983706725, 29.735234215885946, 34.623217922606926, 32.17922606924644]\n",
            "Mean Accuracy: 30.754%\n"
          ]
        }
      ],
      "source": [
        "# Test the kNN on the penguins dataset\n",
        "seed(1)\n",
        "filename = './datasets/Indicadores_municipales.csv'\n",
        "\n",
        "dataset = load_csv(filename)\n",
        "\n",
        "# Convert columns to appropriate data types\n",
        "for i in range(len(dataset[0])-1):\n",
        "    str_column_to_float(dataset, i)\n",
        "\n",
        "# Convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "\n",
        "# Evaluate the algorithm\n",
        "n_folds = 5\n",
        "num_neighbors = 5\n",
        "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
        "\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "html\n"
      ],
      "metadata": {
        "id": "jhsIhQ4j_7VH"
      },
      "id": "jhsIhQ4j_7VH"
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/KNN.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvdivM36_8kH",
        "outputId": "69975279-57d8-4a59-fe12-0da281e2075d"
      },
      "id": "cvdivM36_8kH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/KNN.ipynb to html\n",
            "[NbConvertApp] Writing 624987 bytes to /content/KNN.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}