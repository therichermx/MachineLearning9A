{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "41d0760b-de64-4caf-8a62-c12fee998c7a",
      "metadata": {
        "id": "41d0760b-de64-4caf-8a62-c12fee998c7a"
      },
      "source": [
        "# Underdevelopment level"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0601fbc6-7a81-4d67-a626-b8839ce2b5ec",
      "metadata": {
        "id": "0601fbc6-7a81-4d67-a626-b8839ce2b5ec"
      },
      "source": [
        "1) **Feature Name:** gdo_rezsoc05\n",
        "2) **Problem Type:** Classification\n",
        "3) **Question:** Level of social underdevelopment in 2005 for a newly observed entity\n",
        "\n",
        "\n",
        "\n",
        "*   **Feature Name:** gdo_rezsoc10\n",
        "*   **Problem Type:** Classification\n",
        "*   **Question:** Level of social underdevelopment in 2010 on a recently observed entity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd089502-9422-4a09-a97e-a8ca32382ccd",
      "metadata": {
        "id": "cd089502-9422-4a09-a97e-a8ca32382ccd"
      },
      "source": [
        "![proof.png](attachment:624d3d0d-030a-43ed-89be-694176b45134.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ea2bb70-118e-4cb7-9098-ca519dd279ad",
      "metadata": {
        "id": "6ea2bb70-118e-4cb7-9098-ca519dd279ad"
      },
      "source": [
        "Data extracted from: *https://datos.gob.mx/busca/dataset/indicadores-de-pobreza-pobreza-por-ingresos-rezago-social-y-gini-a-nivel-municipal1990-200-2010*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e46aff-1adf-4c5b-abf5-a06916a10e1a",
      "metadata": {
        "id": "c6e46aff-1adf-4c5b-abf5-a06916a10e1a"
      },
      "source": [
        "#KNN Implementation without special libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d495a6cf-96af-4e3a-a2f9-4a79edd72932",
      "metadata": {
        "id": "d495a6cf-96af-4e3a-a2f9-4a79edd72932"
      },
      "source": [
        "#### CSV Editing / Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab0eb9a8-170b-4dc9-a209-908e6f0584f1",
      "metadata": {
        "id": "ab0eb9a8-170b-4dc9-a209-908e6f0584f1"
      },
      "source": [
        "Before writing any code, the CSV file was edited by hand to remove any unnecessary columns, particularly columns with data relating to years other than 2010, as well as columns with strings that are not needed for the purpose of this program.\n",
        "\n",
        "\n",
        "**REMOVED COLUMNS:** *\"ent,\" \"nom_ent,\" \"mun,\" \"clave_mun,\" \"nom_mun,\" \"pobtot_ajustada,\" \"pobtot_00,\" \"pobtot_05,\" \"porc_pob_15_analfa00,\" \"porc_pob_15_analfa05,\" \"porc_pob614_noasiste00,\" \"porc_pob614_noasiste05,\" \"porc_pob15_basicainc'0,\" \"porc_pob15_basicainc05,\" \"porc_pob_snservsal00,\" \"porc_pob_snservsal05,\" \"porc_vivpisotierra00,\" \"porc_vivpisotierra05,\" \"porc_vivsnsan00,\" \"porc_vivsnsan05,\" \"porc_snaguaent00,\" \"porc_snaguaent05,\" \"porc_vivsndren00,\" \"porc_vivsndren05,\" \"porc_vivsnenergia00,\" \"porc_vivsnenergia05,\" \"porc_vivsnlavadora00,\" \"porc_vivsnlavadora05,\" \"porc_vivsnrefri00,\" \"porc_vivsnrefr05,\" \"irez_soc00,\" \"irez_soc05,\" \"gdo_rezsoc00,\" \"gdo_rezsoc05,\" \"l_ocupnac00,\" \"l_ocupnac05,\" \"p_rez_edu_90,\" \"p_rez_edu_00,\" \"p_ser_sal_00,\" \"p_viv_pisos_90,\" \"p_viv_pisos_00,\" \"p_viv_muros_90,\" \"p_viv_muros_00,\" \"p_viv_techos_90,\" \"p_viv_techos_00,\" \"p_viv_hacin_90,\" \"p_viv_hacin_00,\" \"p_viv_agu_entub_90,\" \"p_viv_agu_entub_00,\" \"p_viv_dren_90,\" \"p_viv_dren_000,\" \"p_viv_elect_90,\" \"p_viv_elect_00,\" \"pobreza_alim_90,\" \"pobreza_alim_00,\" \"pobreza_cap_90,\" \"pobreza_cap_00,\" \"pobreza_patrim_90,\" \"pobreza_patrim_00,\" \"gini_90,\" \"gini_00\".*\n",
        "\n",
        "The column chosen to be the target as stated previously was \"gdo_rezsoc10\". This column was moved to the end of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a53cf3ca-1c1a-4c1a-8616-2cedb67006f2",
      "metadata": {
        "id": "a53cf3ca-1c1a-4c1a-8616-2cedb67006f2"
      },
      "source": [
        "#### Importing and Loading Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cfc391d0-bb52-4f34-aaa6-bb8fc78d6eca",
      "metadata": {
        "id": "cfc391d0-bb52-4f34-aaa6-bb8fc78d6eca"
      },
      "outputs": [],
      "source": [
        "# Importing\n",
        "from csv import reader #Allows us to read CSV files\n",
        "from math import sqrt #Needed for distance calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df28abd8-4537-4ca2-82d8-f4e8124552da",
      "metadata": {
        "id": "df28abd8-4537-4ca2-82d8-f4e8124552da"
      },
      "source": [
        "We define our loading function, which takes a string representing the name of the CSV file as an argument. We then initialize an empty list inside the function to store the data from the CSV file. We open the file in read mode ('r'), create a csv_reader object and pass our file, then iterate through each row in the CSV file.\n",
        "\n",
        "Inside the loop, the we check if the row is empty. If so, skip that iteration and move to the next row. If the row is not empty, appended it to the dataset. This is done to exclude any empty rows.\n",
        "\n",
        "After all rows have been processed, we slice the dataset to exclude the header row, assuming that the first row contains column headers. If the dataset is empty, print a message to indicate that. Finally, we return the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bb408a41-5623-419e-86d5-a77f0b1d7462",
      "metadata": {
        "id": "bb408a41-5623-419e-86d5-a77f0b1d7462"
      },
      "outputs": [],
      "source": [
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "    dataset = list()\n",
        "    with open(filename, 'r') as file: # open in read mode ('r'),\n",
        "        csv_reader = reader(file)\n",
        "        for row in csv_reader:\n",
        "            if not row: # Iterates through each row. If empty it skips the iteration.\n",
        "                continue\n",
        "            dataset.append(row) # Otherwise, it appends the row to the dataset.\n",
        "        # Slicing the dataset\n",
        "    if len(dataset) > 0:\n",
        "        dataset = dataset[1:]  # Exclude the first row\n",
        "    else:\n",
        "        print(\"Dataset is empty or does not contain any rows.\")\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc97e0b-ca04-4777-90b6-e475d19223c7",
      "metadata": {
        "id": "1bc97e0b-ca04-4777-90b6-e475d19223c7"
      },
      "source": [
        "#### Detecting and replacing empty columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99874386-b31e-4a53-939a-33eb12ba92aa",
      "metadata": {
        "id": "99874386-b31e-4a53-939a-33eb12ba92aa"
      },
      "source": [
        "We initialize two lists at the beginning of the function:\n",
        "- **column_sums** to store the cumulative sums of values in each column.\n",
        "- **column_counts** to keep track of the number of non-empty (numeric) values in each column.\n",
        "Both lists are initialized with zeros, and their length is determined by the number of columns in the dataset.\n",
        "\n",
        "With [:-1], we iterate trhough the elemnts of each row, excluding the last element, which is the last column, which is our target and the only column that has non-numeric labels (strings).\n",
        "\n",
        "Each value in the row is checked to see if they are not \"None\". If the value is a non-empty string, then it is converted to float and the result is added to the corresponding column for that column index, then the count in \"column_counts\" increases by 1. If the value is an integer, it is simply added to the appropriate column sum and the \"column_counts\" count is increased by 1\n",
        "\n",
        "After going through all of the rows, an empty list is created where the calculated averages are then stored. Next, the \"column:sums\" list is iterated through, and each sum is divided by the count (if greater than zero). If the count is 0 for a column (i.e., there were no valid numeric values in that column), it appends None to the column_averages list for that column.\n",
        "\n",
        "Finally we return the column_averages list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "83818f1a-c7e1-4eaa-9ac6-c31bed2f3fc9",
      "metadata": {
        "scrolled": true,
        "id": "83818f1a-c7e1-4eaa-9ac6-c31bed2f3fc9"
      },
      "outputs": [],
      "source": [
        "def calculate_column_averages(dataset):\n",
        "    column_sums = [0] * len(dataset[0])\n",
        "    column_counts = [0] * len(dataset[0])\n",
        "\n",
        "    for row in dataset:\n",
        "        for col_idx, value in enumerate(row[:-1]):  # Last column is excluded\n",
        "            if value is not None:\n",
        "                if isinstance(value, str) and value.strip() != '':\n",
        "                    column_sums[col_idx] += float(value)\n",
        "                    column_counts[col_idx] += 1\n",
        "                elif isinstance(value, (int, float)):\n",
        "                    column_sums[col_idx] += value\n",
        "                    column_counts[col_idx] += 1\n",
        "\n",
        "    column_averages = []\n",
        "    for i in range(len(column_sums)):\n",
        "        if column_counts[i] > 0:\n",
        "            average = column_sums[i] / column_counts[i]\n",
        "            column_averages.append(average)\n",
        "        else:\n",
        "            column_averages.append(None)\n",
        "    return column_averages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca71d020-1472-4651-8344-a36c321b5782",
      "metadata": {
        "id": "ca71d020-1472-4651-8344-a36c321b5782"
      },
      "source": [
        "Iterating through each row and column of the dataset, we get the index of the row (row_idx) and the column (col_idx) using enumerate. For each value in the dataset, check if value is None, or, if value is an empty string ''. To ensure if the value is empty or missing data.\n",
        "\n",
        "If the value is empty, the value is replaced with the corresponding column average from the column_averages list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bc2dd1b5-c28d-46af-b17f-7a1589cfbd08",
      "metadata": {
        "id": "bc2dd1b5-c28d-46af-b17f-7a1589cfbd08"
      },
      "outputs": [],
      "source": [
        "def replace_empty_spots_with_averages(dataset, column_averages):\n",
        "    for row_idx, row in enumerate(dataset):\n",
        "        for col_idx, value in enumerate(row[:-1]):  # Exclude the last column\n",
        "            if value is None or value == '':\n",
        "                dataset[row_idx][col_idx] = column_averages[col_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9680f1b-63a0-47a8-b73f-a4e3d65ffba0",
      "metadata": {
        "id": "b9680f1b-63a0-47a8-b73f-a4e3d65ffba0"
      },
      "source": [
        "**Detecting empty spots**\n",
        "\n",
        "In this new section, we initialize a boolean variable to False, using it as a flag of whether any empty spots were detected in the dataset. Then iterate through the rows of the dataset and the columns of each row.\n",
        "\n",
        "Just like before, for each value in the dataset, check if value is None or if value is an empty string ''. If an empty spot is detected, set empty_spots_detected to True.\n",
        "\n",
        "When the argument becomes True, the row and column for the emtpy spot is printed, then the value of \"empty_spots_detected\" is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b9ef180c-6420-4814-8500-75fb2ac900fb",
      "metadata": {
        "id": "b9ef180c-6420-4814-8500-75fb2ac900fb"
      },
      "outputs": [],
      "source": [
        "def print_empty_spots(dataset, printempty):\n",
        "    empty_spots_detected = False  # Initialize to False\n",
        "    for row_idx, row in enumerate(dataset):\n",
        "        for col_idx, value in enumerate(row[:-1]):  # Loop through each value in the row\n",
        "            if value is None or value == '':\n",
        "                empty_spots_detected = True  # Update to True if an empty spot is detected\n",
        "                if printempty:\n",
        "                    print(f\"Empty spot at row {row_idx}, column {col_idx}\")\n",
        "    return empty_spots_detected"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67f1693c-6667-4dd3-95b4-41ced4fb0824",
      "metadata": {
        "id": "67f1693c-6667-4dd3-95b4-41ced4fb0824"
      },
      "source": [
        "**Replacing empty spots**\n",
        "\n",
        "First, we call the print_empty_spots function with the dataset and a boolean argument and assign the result to empty_spots_detected, then check the value of empty_spots_detected. If True, proceed to clean and impute the data. If it's False, print \"No empty spots\".\n",
        "\n",
        "If empty spots were detected, print a message and separate it for clarity. Then calculate the column averages using the calculate_column_averages function and replace empty spots with the column averages using the replace_empty_spots_with_averages function. Finally print \"Converting Done\" to indicate that the process has finished."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "43d4e2e1-bdd6-4529-896a-971bcf16290e",
      "metadata": {
        "id": "43d4e2e1-bdd6-4529-896a-971bcf16290e"
      },
      "outputs": [],
      "source": [
        "def empty_reduction(dataset, printempty):\n",
        "    empty_spots_detected = print_empty_spots(dataset, printempty)\n",
        "    if empty_spots_detected:\n",
        "        print(\"Converting empty spots to averages of the column\")\n",
        "        print(\"================================================\")\n",
        "        # Calculate column averages\n",
        "        column_averages = calculate_column_averages(dataset)\n",
        "        # Replace empty spots with column averages\n",
        "        replace_empty_spots_with_averages(dataset, column_averages)\n",
        "        print(\"Converting Done\")\n",
        "    else:\n",
        "        print(\"No empty spots\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8577da1-3452-4637-a394-301370628271",
      "metadata": {
        "id": "a8577da1-3452-4637-a394-301370628271"
      },
      "source": [
        "#### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7940c85-b9a1-4afc-be86-1f1e50b59548",
      "metadata": {
        "id": "d7940c85-b9a1-4afc-be86-1f1e50b59548"
      },
      "source": [
        "In this section, we take a specified column for the current row, then remove any extra whitespace using strip(), and convert the string to float.\n",
        "\n",
        "We need to convert strings of numbers into actual numerical values because we need to calculate the distance between datapoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a305557b-bb54-4243-b987-39f9b3b808e5",
      "metadata": {
        "id": "a305557b-bb54-4243-b987-39f9b3b808e5"
      },
      "outputs": [],
      "source": [
        "def str_column_to_float(dataset, column):\n",
        "    for row in dataset:\n",
        "        cell = row[column]\n",
        "        if isinstance(cell, str):  # Check if it's a string\n",
        "            cell = cell.strip()\n",
        "            if cell:  # Check if the stripped cell is not empty\n",
        "                row[column] = float(cell)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec3dfea-e52e-4f93-82a0-d22fd976e20d",
      "metadata": {
        "id": "8ec3dfea-e52e-4f93-82a0-d22fd976e20d"
      },
      "source": [
        "We iterate through the dataset and create a list called ***class_values***, which contains all the values from that particular column. We then create a set called ***unique*** to store the unique values from the *class_values* list, to ensure that each unique value is considered only once.\n",
        "\n",
        "\n",
        "We initialize an empty dictionary called \"lookup\". The dictionary will be used to link each unique string value to a unique integer. The key will be the string value, and the value will be the corresponding integer. We iterate through the unique values and fill the lookup dictionary, checking that the value is not an empty string or a space before adding it to the lookup. This is to avoid including missing or empty values in the lookup table.\n",
        "\n",
        "We calculate the most common value in the *class_values* list using the max function with the key argument set to class_values.count. Then, we go through the entire dataset again. If the cell_value is None or an empty string, we replace it with the most common value in the column to handle missing data. If the cell_value is a valid non-empty string, replace it with the corresponding integer value from the lookup table.\n",
        "\n",
        "Finally, return the lookup dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "95c6b27a-c8fd-4cbe-94e3-9162a2215d6d",
      "metadata": {
        "id": "95c6b27a-c8fd-4cbe-94e3-9162a2215d6d"
      },
      "outputs": [],
      "source": [
        "def str_column_to_int(dataset, column):\n",
        "    class_values = [row[column] for row in dataset]\n",
        "    unique = set(class_values)\n",
        "    lookup = dict()\n",
        "    most_common_value = max(set(class_values), key=class_values.count)\n",
        "\n",
        "    for i, value in enumerate(unique):\n",
        "        if value != '' and value != ' ':\n",
        "            lookup[value] = i\n",
        "\n",
        "    for row in dataset:\n",
        "        cell_value = row[column]\n",
        "        if cell_value is None or cell_value == '':\n",
        "            row[column] = most_common_value\n",
        "        else:\n",
        "            row[column] = lookup[cell_value]\n",
        "    return lookup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a273f0-9688-4035-926d-d6d2b4e5b13c",
      "metadata": {
        "id": "e8a273f0-9688-4035-926d-d6d2b4e5b13c"
      },
      "source": [
        "We create an empty list to store the minimum and maximum values for each column, then go through the columns of the dataset using range(len(dataset[0])) to iterate from 0 to the number of columns in the first row of the dataset. Inside the loop, we create a col_values list by going through each row in the dataset and selecting the value at the current column index (i) for each row.\n",
        "\n",
        "We then calculate the minimum and maximum values in the col_values list and append them to the minmax list. After processing all columns, return the minmax list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "09479d5d-1d96-40d3-b059-291764e3c9d7",
      "metadata": {
        "id": "09479d5d-1d96-40d3-b059-291764e3c9d7"
      },
      "outputs": [],
      "source": [
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "    minmax = list() # empty list to store the min / max values for each column.\n",
        "    for i in range(len(dataset[0])): # Iterates through each column of the dataset\n",
        "        col_values = [row[i] for row in dataset] # Extracts the values from the current column\n",
        "        value_min = min(col_values)\n",
        "        value_max = max(col_values)\n",
        "        minmax.append([value_min, value_max])\n",
        "    return minmax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "defc82b7-db59-4a0f-a8b9-1dae66c7c2fb",
      "metadata": {
        "id": "defc82b7-db59-4a0f-a8b9-1dae66c7c2fb"
      },
      "source": [
        "For each value in the dataset, rescale the value to [0, 1].\n",
        "\n",
        "Subtract the minimum for that column *(minmax[i][0])* from the value, then divide by the range of values for that column *(minmax[i][1] - minmax[i][0])*.\n",
        "\n",
        "Then reassign back to the original location in the dataset *(row[i])*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f8846a63-17bd-48cc-8d6a-ea9ebef95fac",
      "metadata": {
        "id": "f8846a63-17bd-48cc-8d6a-ea9ebef95fac"
      },
      "outputs": [],
      "source": [
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "    for row in dataset:\n",
        "        for i in range(len(row)): # Iterates through each row in the dataset and then through each column within that row.\n",
        "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f31024d-d2b2-4a0a-928b-795d208ecf20",
      "metadata": {
        "id": "1f31024d-d2b2-4a0a-928b-795d208ecf20"
      },
      "source": [
        "The first step for KNN is to calculate the distance between two rows in a dataset. The smaller the value, the more similar the two will be. A value of 0 means that there is no difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "adc8393b-5a3c-4001-9649-db9985388625",
      "metadata": {
        "id": "adc8393b-5a3c-4001-9649-db9985388625"
      },
      "outputs": [],
      "source": [
        "# Calculate the Euclidean distance between two vectors\n",
        "def euclidean_distance(row1, row2):\n",
        "    distance = 0.0\n",
        "    for i in range(len(row1) - 1):\n",
        "        distance += (row1[i] - row2[i]) ** 2\n",
        "    return sqrt(distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7286a327-c232-4b5f-a5f7-71f72f32a11d",
      "metadata": {
        "id": "7286a327-c232-4b5f-a5f7-71f72f32a11d"
      },
      "source": [
        "After, we need to calculate the distance between each observation in the dataset to the new piece of data. Then sort all of the observations in the training dataset by their distance to the new data.\n",
        "\n",
        "We select the top *k* to return as the most similar neighbors.\n",
        "\n",
        "Here, lambda defines an anonymous function that takes a single tuple and returns the second element of the tuple, *tup[1]*. The data point and its distance from the test_row are added as a tuple to the distances list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8cb69e71-aa85-4741-9c0d-709684668233",
      "metadata": {
        "id": "8cb69e71-aa85-4741-9c0d-709684668233"
      },
      "outputs": [],
      "source": [
        "# Locate the most similar neighbors\n",
        "def get_neighbors(train, test_row, num_neighbors):\n",
        "    distances = list() # Initialize an Empty List for Distances\n",
        "    for train_row in train:\n",
        "        dist = euclidean_distance(test_row, train_row)\n",
        "        distances.append((train_row, dist))\n",
        "    distances.sort(key=lambda tup: tup[1])\n",
        "    neighbors = list()\n",
        "    for i in range(num_neighbors):\n",
        "        neighbors.append(distances[i][0])\n",
        "    return neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ceb3870-de00-4c3f-9807-89bcefae963e",
      "metadata": {
        "id": "4ceb3870-de00-4c3f-9807-89bcefae963e"
      },
      "source": [
        "After identifying the classes of the K nearest neighbors for a given data point, we have a list of output values representing the classes of these neighbors.\n",
        "\n",
        "The max() function is then applied to this list of output values to return the maximum value in that list (in this case, the classes).\n",
        "\n",
        "**train:** The training dataset containing labeled data points.\n",
        "\n",
        "**test_row:** The data point for the prediction.\n",
        "\n",
        "**num_neighbors:** The number of nearest neighbors to consider for the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e57ea3a5-b826-4032-8572-fa557c8c24d6",
      "metadata": {
        "id": "e57ea3a5-b826-4032-8572-fa557c8c24d6"
      },
      "outputs": [],
      "source": [
        "# Make a prediction with neighbors\n",
        "def predict_classification(train, test_row, num_neighbors):\n",
        "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
        "    output_values = [row[-1] for row in neighbors]\n",
        "    prediction = max(set(output_values), key=output_values.count) # finds the most common output label\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2167a648-82da-4710-aca0-bd153d1bca8c",
      "metadata": {
        "id": "2167a648-82da-4710-aca0-bd153d1bca8c"
      },
      "source": [
        "#### Main Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e7e699d-8090-4b04-882a-e6d4499de006",
      "metadata": {
        "id": "2e7e699d-8090-4b04-882a-e6d4499de006"
      },
      "source": [
        "Load a CSV dataset from the file, then iterate through each column excluding the last, which is the target variable. Inside the loop, call the str_column_to_float function to convert each string value in the column to a floating-point number.\n",
        "\n",
        "Then call the empty_reduction function to detect and handle empty or missing values, with False as the printempty argument so it does not print information about empty spots.\n",
        "\n",
        "Call the str_column_to_int function to convert the target variable from string labels to integer representations. Set num_neighbors to 5 nearest neighbors during the classification. Set a new observation, ***row***, as new data for a classification prediction.\n",
        "\n",
        "Call predict_classification to make a classification prediction for the row data. The predicted label is stored and we then print the new observation (row) and the predicted label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8b92828c-f2ae-4ed8-847e-037a8d543545",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b92828c-f2ae-4ed8-847e-037a8d543545",
        "outputId": "8aac1769-3532-41fb-e39d-bc5fa10ad0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting empty spots to averages of the column\n",
            "================================================\n",
            "Converting Done\n",
            "Data=[20.3309874, 6.312496265, 16.01849139, 20.03520906, 7.216375202, 15.41742921, 27.00382583, 21.8836851, 28.55256295, 16.94836957, 4.465343332, 51.86079564, 20.36619717, 79.75088181, 74.54736258, 4.592411399, 2363, 1239, 46668, 6778, 20891, 11920, 3626, 29946, 16723, 16965, 86306, 52352, 6303, 74357, 80588, 20041, 14295, 33504, 125, 312, 1.370063305, 2.641284704, 3.160161018, 5.847710371, 5.7240417, 1.696373701, 1.382647991, 3.536691666, 5.998271704, 1.854506731, 1.070803642, 4.496376753, 4.08946681, 4.604298115, 75589, 3.83435297, 2.575343132, 21.29608154, 20.60673904, 1.707235098, 17.3696003, 2.168817043, 1.037015915, 15.72911072, 23.89793015, 14.16432953, 2.289044291, 777, 62.4, 28.8, 44.1, 27.4, 11.9, 20.6, 20.6, 7.5, 4, 10.3, 18.7, 24.6, 0.202], Predicted: 2\n"
          ]
        }
      ],
      "source": [
        "filename = './datasets/Indicadores_municipales.csv'\n",
        "dataset = load_csv(filename)\n",
        "\n",
        "for i in range(len(dataset[0])-1): # iterate through each column excluding the target variable\n",
        "    str_column_to_float(dataset, i) # convert string to float.\n",
        "\n",
        "empty_reduction(dataset, False)\n",
        "\n",
        "# Convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "\n",
        "# Define Neighbors\n",
        "num_neighbors = 5\n",
        "# Define a new observation\n",
        "row = [20.3309874, 6.312496265, 16.01849139, 20.03520906, 7.216375202, 15.41742921, 27.00382583, 21.8836851, 28.55256295,\n",
        "       16.94836957, 4.465343332, 51.86079564, 20.36619717, 79.75088181, 74.54736258, 4.592411399, 2363, 1239, 46668, 6778,\n",
        "       20891, 11920, 3626, 29946, 16723, 16965, 86306, 52352, 6303, 74357, 80588, 20041, 14295, 33504, 125, 312,\n",
        "       1.370063305, 2.641284704, 3.160161018, 5.847710371, 5.7240417, 1.696373701, 1.382647991, 3.536691666, 5.998271704,\n",
        "       1.854506731, 1.070803642, 4.496376753, 4.08946681, 4.604298115, 75589, 3.83435297, 2.575343132, 21.29608154,\n",
        "       20.60673904, 1.707235098, 17.3696003, 2.168817043, 1.037015915, 15.72911072, 23.89793015, 14.16432953, 2.289044291,\n",
        "       777, 62.4, 28.8, 44.1, 27.4, 11.9, 20.6, 20.6, 7.5, 4, 10.3, 18.7, 24.6, 0.202]\n",
        "\n",
        "\n",
        "# Predict the label\n",
        "label = predict_classification(dataset, row, num_neighbors)\n",
        "print('Data=%s, Predicted: %s' % (row, label))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3d12b1f-f026-432c-98c3-9bbe9198ae2f",
      "metadata": {
        "id": "c3d12b1f-f026-432c-98c3-9bbe9198ae2f"
      },
      "source": [
        "### Loss and Optimization Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af5e12ec-a70c-4987-b8fe-5f7ae1ab40c6",
      "metadata": {
        "id": "af5e12ec-a70c-4987-b8fe-5f7ae1ab40c6"
      },
      "source": [
        "A loss function is used to measure the accuracy of a model’s predictions. It calculates the difference between the predicted output and the actual output for each training sample.\n",
        "\n",
        "KNN does not inherently involve a loss function in the same way as supervised learning models.\n",
        "No function is fitted to the data, and so, no optimization is done\n",
        "\n",
        "However we can calculate the accuracy of our predictions.\n",
        "\n",
        "Cross-validation is a way to evaluate the performance of the KNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9b6bc36f-084b-4598-84b8-b0b2506eecf9",
      "metadata": {
        "id": "9b6bc36f-084b-4598-84b8-b0b2506eecf9"
      },
      "outputs": [],
      "source": [
        "# Importing\n",
        "from random import seed\n",
        "from random import randrange"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f27c66-1dda-4c74-9bff-5e59e4247801",
      "metadata": {
        "id": "35f27c66-1dda-4c74-9bff-5e59e4247801"
      },
      "source": [
        "\"Folds\" refers to the subdivisions into which a dataset is divided for evaluating\n",
        "\n",
        "For each fold, we iterate n times. Within each iteration, we create a new fold and populate it with fold_size samples randomly selected from the dataset copy.\n",
        "\n",
        "We use randrange to select a random index from dataset_copy, and add it to the fold. We then remove it from dataset_copy to avoid duplication.\n",
        "\n",
        "Finally, the fold is added to dataset_split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "dbcd7167-f7eb-4cb8-945b-879a269ce280",
      "metadata": {
        "id": "dbcd7167-f7eb-4cb8-945b-879a269ce280"
      },
      "outputs": [],
      "source": [
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "    dataset_split = list()\n",
        "    dataset_copy = list(dataset)\n",
        "    fold_size = int(len(dataset) / n_folds) # Calculates the size of each fold\n",
        "    for _ in range(n_folds):\n",
        "        fold = list()\n",
        "        while len(fold) < fold_size:\n",
        "            index = randrange(len(dataset_copy)) # select a random index from dataset_copy\n",
        "            fold.append(dataset_copy.pop(index)) # remove from dataset_copy to avoid duplication.\n",
        "        dataset_split.append(fold)\n",
        "    return dataset_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f28683b8-b61a-444a-ac31-6ec3d5511f0a",
      "metadata": {
        "id": "f28683b8-b61a-444a-ac31-6ec3d5511f0a"
      },
      "source": [
        "Predict the labels for the test dataset using the KNN algorithm. Initialize an empty list to store the predicted class labels for each data point in the test dataset.\n",
        "\n",
        "For each data point in the test dataset, call predict_classification. Append prediction to predictions list, continue this process for all data points in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "cffa76a3-ece1-46ca-880e-7799be3ca2ce",
      "metadata": {
        "id": "cffa76a3-ece1-46ca-880e-7799be3ca2ce"
      },
      "outputs": [],
      "source": [
        "# kNN Algorithm\n",
        "def k_nearest_neighbors(train, test, num_neighbors):\n",
        "    predictions = list()\n",
        "    for row in test:\n",
        "        output = predict_classification(train, row, num_neighbors)\n",
        "        predictions.append(output)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "569e1e5d-4fcf-40cc-bee0-89ab0e29bdba",
      "metadata": {
        "id": "569e1e5d-4fcf-40cc-bee0-89ab0e29bdba"
      },
      "source": [
        "Comparing the predicted labels with the actual labels\n",
        "\n",
        "Initialize a variable to keep track of the number of correct predictions. For each data point, check if the actual label in the actual list (at index i) matches the predicted label in the predicted list (at index i). If they match, it means the prediction is correct, and ***correct*** is incremented by 1.\n",
        "\n",
        "After looping through all data points, calculate the accuracy percentage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "bae6d171-273d-463f-ae25-7eae67e3a66f",
      "metadata": {
        "id": "bae6d171-273d-463f-ae25-7eae67e3a66f"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "    correct = 0 # keep track of correct predictions\n",
        "    for i in range(len(actual)):\n",
        "        if actual[i] == predicted[i]: #  check if the actual label matches the predicted label\n",
        "            correct += 1\n",
        "    return correct / float(len(actual)) * 100.0 # get percentage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f41ff3a-b314-406b-94e5-2f7db74bfcab",
      "metadata": {
        "id": "4f41ff3a-b314-406b-94e5-2f7db74bfcab"
      },
      "source": [
        "Here we apply Cross-validation, which is when the dataset is randomly split up into 'k' groups. One of the groups is used as the test set and the rest are used as the training set.\n",
        "\n",
        "Call cross_validation_split with the dataset and n_folds arguments. For each fold, a training set and a test set are created. The training set is constructed by combining all the folds except the current fold. The line train_set = sum(train_set, []) is used to concatenate the lists representing each fold into a single training set list.\n",
        "\n",
        "A separate test set is created for each fold by copying the data points from the fold. Each row in the fold is copied to the test set, and the class label (the last element in each row) is set to None to simulate a scenario where the true labels are hidden during testing.\n",
        "\n",
        "The algorithm function is then called with the training set and test set for the current fold, we return predictions for the test set. The actual class labels for the test set are extracted from the current fold, and the accuracy_metric function is used to calculate the accuracy score by comparing the actual and predicted labels.\n",
        "\n",
        "The accuracy score is appended to the scores list for the current fold. After looping through all the folds, we return the list of evaluation scores, one for each fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "dba6ea44-1989-418c-aff0-c345900f02f6",
      "metadata": {
        "id": "dba6ea44-1989-418c-aff0-c345900f02f6"
      },
      "outputs": [],
      "source": [
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "    folds = cross_validation_split(dataset, n_folds)\n",
        "    scores = list()\n",
        "    for fold in folds:\n",
        "        train_set = list(folds) # create a training set by combining all folds except the current fold.\n",
        "        train_set.remove(fold)\n",
        "        train_set = sum(train_set, []) # separate the current fold as the test set.\n",
        "        test_set = list()\n",
        "        for row in fold: # preparing the test set by creating a copy of each row in the fold\n",
        "            row_copy = list(row)\n",
        "            test_set.append(row_copy) # Add copied row to the test_set\n",
        "            row_copy[-1] = None # remove the label from the row\n",
        "        predicted = algorithm(train_set, test_set, *args)\n",
        "        actual = [row[-1] for row in fold] # Extract the actual labels from the current fold.\n",
        "        accuracy = accuracy_metric(actual, predicted)\n",
        "        scores.append(accuracy)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0200d018-1f2e-4762-a5c5-4871e34f317c",
      "metadata": {
        "id": "0200d018-1f2e-4762-a5c5-4871e34f317c"
      },
      "source": [
        "KNN itself doesn't have an usual training phase with model parameters, but cross-validation helps in understanding how well the algorithm performs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90b5dc38-dd8c-4473-a396-ae955b159423",
      "metadata": {
        "id": "90b5dc38-dd8c-4473-a396-ae955b159423"
      },
      "source": [
        "#### Main Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d6c13c0-c767-4ed9-9677-4a59077ebdb3",
      "metadata": {
        "id": "3d6c13c0-c767-4ed9-9677-4a59077ebdb3"
      },
      "source": [
        "seed(1) is called to set the random seed for any random number generation in the code.\n",
        "The rest of the steps are the same as the previous example above, with the only exception that we print out the information about empty spots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "b9453c3f-60fd-4b3a-8e97-c722abc0bd98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9453c3f-60fd-4b3a-8e97-c722abc0bd98",
        "outputId": "241a617d-1bec-4b78-f093-9f9c28317135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty spot at row 1044, column 43\n",
            "Empty spot at row 1990, column 43\n",
            "Converting empty spots to averages of the column\n",
            "================================================\n",
            "Converting Done\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Muy bajo': 0, 'Muy alto': 1, 'Bajo': 2, 'Alto': 3, 'Medio': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Test the kNN on the Iris Flowers dataset\n",
        "seed(1)\n",
        "filename = './datasets/Indicadores_municipales.csv'\n",
        "dataset = load_csv(filename)\n",
        "\n",
        "# Convert columns to appropriate data types\n",
        "for i in range(len(dataset[0])-1):\n",
        "    str_column_to_float(dataset, i)\n",
        "\n",
        "# Convert empty column data to the aveargae of said column\n",
        "empty_reduction(dataset, True) # False = Do Not Print empty rows\n",
        "\n",
        "# Convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd31b688-a21b-446f-9d22-d7b9dab916b8",
      "metadata": {
        "id": "cd31b688-a21b-446f-9d22-d7b9dab916b8"
      },
      "source": [
        "Set the number of folds and nearest neighbors to 5.\n",
        "Call evaluate_algorithm function, return a list of accuracy scores, where each score corresponds to the performance of the k-NN algorithm on a different fold of the dataset.\n",
        "\n",
        "Print out the list of accuracy scores obtained from cross-validation. Then calculate the mean accuracy by taking the sum of all the accuracy scores and dividing it by the total number of scores, this gives the average accuracy over all folds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f0e24c08-fd60-4d64-8d2e-c5d13bb1d112",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0e24c08-fd60-4d64-8d2e-c5d13bb1d112",
        "outputId": "96f06449-69ba-46ed-96b2-06112dc8187a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [64.76578411405295, 68.22810590631364, 67.20977596741345, 68.63543788187373, 64.15478615071282]\n",
            "Mean Accuracy: 66.599%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the algorithm\n",
        "n_folds = 5\n",
        "num_neighbors = 5\n",
        "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
        "\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5045e3d2-a539-4f9a-bd19-e9aaba37c5db",
      "metadata": {
        "id": "5045e3d2-a539-4f9a-bd19-e9aaba37c5db"
      },
      "source": [
        "## KNN Using SciKit Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e4af627-0150-4744-832a-8a41640054b6",
      "metadata": {
        "id": "1e4af627-0150-4744-832a-8a41640054b6"
      },
      "source": [
        "Scikit-learn, is a machine learning library in Python. Among its diverse set of algorithms, k-Nearest Neighbors (KNN) stands as one of the simplest yet effective classification and regression methods.\n",
        "We'll focus on using scikit-learn to apply KNN in practice, examining the steps required to prepare data, train a KNN model, and evaluate its performance. We'll also touch on key considerations, such as selecting the appropriate number of neighbors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58a9428c-eab8-43b4-bcc0-e462b765c633",
      "metadata": {
        "id": "58a9428c-eab8-43b4-bcc0-e462b765c633"
      },
      "source": [
        "We use %reset to clear out saved variables and restart the kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "26c3d530-87a6-4e1c-b5ac-ea99aec5dc7c",
      "metadata": {
        "id": "26c3d530-87a6-4e1c-b5ac-ea99aec5dc7c"
      },
      "outputs": [],
      "source": [
        "# Clear data\n",
        "%reset -f"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea1afd62-0c7e-4f07-954f-14d379d5d736",
      "metadata": {
        "id": "ea1afd62-0c7e-4f07-954f-14d379d5d736"
      },
      "source": [
        "We import the necessary packages for this section\n",
        "\n",
        "1. **Pandas (pd)**:\n",
        "    - Pandas is used for working with structured data, including loading, exploring, and preprocessing datasets.\n",
        "\n",
        "2. **scikit-learn (sklearn)**:\n",
        "   - Scikit-learn is a comprehensive machine learning library that provides tools for data preprocessing, modeling, evaluation, and more.\n",
        "\n",
        "4. **NumPy (numpy)**:\n",
        "   - NumPy is used for numerical operations, including working with arrays and mathematical operations.\n",
        "\n",
        "5. **Seaborn (sns) and Matplotlib (plt)**:\n",
        "   - Seaborn and Matplotlib are used for data visualization and plotting.\n",
        "\n",
        "6. **Warnings**:\n",
        "   - The warnings package is used for warning output manipulation.\n",
        "\n",
        "7. **StandardScaler, LabelEncoder**:\n",
        "   - StandardScaler is used for feature scaling, while LabelEncoder is used for encoding categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "22569083-08f1-451d-9425-2f1e3368eb24",
      "metadata": {
        "id": "22569083-08f1-451d-9425-2f1e3368eb24"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # For working with data frames\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np  # For numerical operations\n",
        "import seaborn as sns  # For plotting\n",
        "import matplotlib.pyplot as plt  # For plotting\n",
        "import warnings # For warning output manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5d10e85-b46a-4e62-839b-36423e9708c7",
      "metadata": {
        "id": "a5d10e85-b46a-4e62-839b-36423e9708c7"
      },
      "source": [
        "Loading the dataset as a pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9744032e-0c7d-4352-8d73-c65e885e7213",
      "metadata": {
        "id": "9744032e-0c7d-4352-8d73-c65e885e7213"
      },
      "outputs": [],
      "source": [
        "# Load a CSV dataset\n",
        "df = pd.read_csv(\"./datasets/Indicadores_municipales.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb202bc-b539-4201-9209-15f7bae00f36",
      "metadata": {
        "id": "bfb202bc-b539-4201-9209-15f7bae00f36"
      },
      "source": [
        "Here we split a dataset into two components: the feature matrix ***X*** and the target variable vector ***y***.\n",
        "\n",
        "The purpose of ***X*** is to store the feature matrix, which includes all the features used to make predictions. We create it by dropping the 'gdo_rezsoc05' (target) column from the DataFrame.\n",
        "\n",
        "The ***y*** variable stores the target variable, we assign it the values of the 'gdo_rezsoc05' column from the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c053eff6-b839-46d6-b5d4-fc7a9607eaf3",
      "metadata": {
        "id": "c053eff6-b839-46d6-b5d4-fc7a9607eaf3"
      },
      "outputs": [],
      "source": [
        "# Split the data into features (X) and target (y)\n",
        "X = df.drop('gdo_rezsoc10', axis=1)\n",
        "y = df['gdo_rezsoc10']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fdb205d-2942-4adc-aa3a-fdb5eb1a6c37",
      "metadata": {
        "id": "9fdb205d-2942-4adc-aa3a-fdb5eb1a6c37"
      },
      "source": [
        "We calculate the column-wise averages for all columns in the feature matrix ***X***, and then replace empty, NaN (Not a Number), or whitespace (' ') entries in the same matrix with their respective column averages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "706da06e-528a-4bec-820b-273d895054d0",
      "metadata": {
        "id": "706da06e-528a-4bec-820b-273d895054d0"
      },
      "outputs": [],
      "source": [
        "# Calculate the column-wise averages for all columns except the target column\n",
        "column_means = X.mean()\n",
        "\n",
        "# Replace empty, NaN, or ' ' entries with the column average\n",
        "X = X.fillna(column_means).replace(' ', column_means)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10ae3645-da1e-480d-9b0d-5456de000812",
      "metadata": {
        "id": "10ae3645-da1e-480d-9b0d-5456de000812"
      },
      "source": [
        "We create a new variable *y_non_empty* that contains only the non-empty and non-whitespace class labels from the original y. This step is performed to exclude empty or ' ' labels when calculating the most common class label and when replacing empty labels later.\n",
        "\n",
        "*most_common_label* determines the most common class label in the *y_non_empty* variable. We first use the *value_counts()* method to count the occurrences of each unique class label and then return the index (class label) associated with the maximum count.\n",
        "\n",
        "*y = y.copy()* creates a copy of the original y to avoid potential issues associated with the SettingWithCopyWarning. *y.loc[y == ' ']* replaces any empty or ' ' class labels in the original ***y*** with the most common class label found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "40272f91-e6f6-4bce-954b-aac90c1ca372",
      "metadata": {
        "id": "40272f91-e6f6-4bce-954b-aac90c1ca372"
      },
      "outputs": [],
      "source": [
        "# Ignore empty or ' ' when assigning unique class labels\n",
        "y_non_empty = y[y != ' ']\n",
        "\n",
        "# Find the most common class label\n",
        "most_common_label = y_non_empty.value_counts().idxmax()\n",
        "\n",
        "# Replace empty or ' ' entries with the most common class label\n",
        "y = y.copy()  # Create a copy of y to avoid SettingWithCopyWarning\n",
        "y.loc[y == ' '] = most_common_label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f803ac44-8035-4b62-ac62-94d6441250d6",
      "metadata": {
        "id": "f803ac44-8035-4b62-ac62-94d6441250d6"
      },
      "source": [
        "*le = LabelEncoder()* creates an instance of the LabelEncoder class where we then apply the label encoding transformation to the target variable ***y***. It assigns a unique numerical label to each distinct class in the target variable.\n",
        "\n",
        "*train_test_split* is a function from scikit-learn used for splitting a dataset into training and test sets. ***X*** is the feature matrix, and ***y*** is the target variable with encoded labels. *test_size=0.2* specifies that 20% of the data will be allocated to the test set, and the remaining 80% will be used for training. The data is randomly shuffled before the split. *random_state=0* sets a random seed to ensure that the data split is reproducible.\n",
        "\n",
        "In the end we are left with four sets:\n",
        "- X_train: The feature matrix for training.\n",
        "- X_test: The feature matrix for testing.\n",
        "- y_train: The target variable (with encoded labels) for training.\n",
        "- y_test: The target variable (with encoded labels) for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e9c4504e-0122-4885-ac97-22d3ab6a5d9b",
      "metadata": {
        "id": "e9c4504e-0122-4885-ac97-22d3ab6a5d9b"
      },
      "outputs": [],
      "source": [
        "# Encode the labels using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3c9da0d-b7c7-496b-b9f1-8d113c8be13f",
      "metadata": {
        "id": "e3c9da0d-b7c7-496b-b9f1-8d113c8be13f"
      },
      "source": [
        "Create an instance of the StandardScaler class. Standardization (or z-score normalization) involves transforming the data so that it has a mean of 0 and a standard deviation of 1. It centers the data around the mean and scales it to have consistent units.\n",
        "\n",
        "The fit_transform method is used to both fit the scaling parameters (mean and standard deviation) to the training set and transform the training set's features simultaneously. The result is that the features in X_train are standardized. The transform method on the test set is used to apply the scaling parameters obtained from the training set. This ensures that the same scaling is applied consistently to both the training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "43ae23b6-f608-498a-abe2-5ffcb4b4da31",
      "metadata": {
        "id": "43ae23b6-f608-498a-abe2-5ffcb4b4da31"
      },
      "outputs": [],
      "source": [
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c033072-3079-47b1-9501-cdd5d99d18d7",
      "metadata": {
        "id": "4c033072-3079-47b1-9501-cdd5d99d18d7"
      },
      "source": [
        "Initialize a KNN classifier and specify the number of nearest neighbors to consider when making predictions (in this case 5). *knn.fit(X_train, y_train)* trains the KNN classifier. *X_train* represents the training set's feature matrix, and *y_train* represents the class labels.\n",
        "\n",
        "*y_pred = knn.predict(X_test)* applies the trained KNN classifier to the test set. For each data point in X_test, the KNN algorithm identifies the k (in this case, 5) nearest neighbors from the training data, and the class label that occurs most frequently among these neighbors is assigned as the predicted class label for the test data point. The predicted labels are stored in the y_pred variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "3d16a6cc-9da8-4bf5-8954-ffd1b2875d20",
      "metadata": {
        "id": "3d16a6cc-9da8-4bf5-8954-ffd1b2875d20"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc65e3e6-e57b-4fd6-8818-8672c60607b5",
      "metadata": {
        "id": "bc65e3e6-e57b-4fd6-8818-8672c60607b5"
      },
      "source": [
        "Calculate the accuracy of the model.\n",
        "\n",
        "The accuracy_score function from scikit-learn is used to compare the true labels (y_test) and the predicted labels (y_pred) and compute the accuracy, which is the ratio of correctly predicted labels to the total number of data points in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "b22995e2-55d6-4d83-8a95-49252147ede2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b22995e2-55d6-4d83-8a95-49252147ede2",
        "outputId": "da630116-8dca-4319-b09f-3a7d248d3bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 81.301%\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy_percentage = round(accuracy * 100, 3)\n",
        "print(\"Accuracy: {:.3f}%\".format(accuracy_percentage))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f919094b-8b11-46a9-b129-1d243802d7b7",
      "metadata": {
        "id": "f919094b-8b11-46a9-b129-1d243802d7b7"
      },
      "source": [
        "#### Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f1c187b-a440-480d-8da8-f161518a1592",
      "metadata": {
        "id": "3f1c187b-a440-480d-8da8-f161518a1592"
      },
      "source": [
        "Stratified cross-validation is a variation of the k-fold cross-validation technique, the dataset is divided into k subsets (folds) just like regular k-fold cross-validation. However, the key difference is that it ensures that each fold maintains the same class distribution as the original dataset.\n",
        "\n",
        "- If the dataset has 80% class A and 20% class B, there's a chance that one or more folds may have a very low representation of class B (e.g., 100% class A).\n",
        "- In stratified cross-validation, the algorithm will ensure that each fold roughly maintains the 80-20 class distribution. So, each fold will have a similar proportion of class A and class B instances.\n",
        "\n",
        "We perform stratified cross-validation for different values of k and then calculate the accuracy scores, this allows us to evaluate the performance of a K-Nearest Neighbors (KNN) classifier for various values of the n_neighbors parameter (k). The accuracy scores are then plotted on a line graph to help us select the best value of k."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bc9cfef-ffe9-4cef-81dd-cd376cb332a8",
      "metadata": {
        "id": "6bc9cfef-ffe9-4cef-81dd-cd376cb332a8"
      },
      "source": [
        "Suppressing a specific warning message related to class population in scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "e7aa5742-f05a-4967-8fce-292173126004",
      "metadata": {
        "id": "e7aa5742-f05a-4967-8fce-292173126004"
      },
      "outputs": [],
      "source": [
        "# Suppress the specific warning about the least populated class\n",
        "warnings.filterwarnings(\"ignore\", message=\"The least populated class in y has only 2 members\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b84a20-95a8-488f-baac-657517f0390f",
      "metadata": {
        "id": "32b84a20-95a8-488f-baac-657517f0390f"
      },
      "source": [
        "Generate a list of k values ranging from 1 to 30 (inclusive). Then initialize an empty list called scores to store the mean cross-validation scores for each value of k.\n",
        "\n",
        "We then scale the features in the matrix ***X*** using the StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "4a86a5cb-fd79-4677-aec4-52c04d799955",
      "metadata": {
        "id": "4a86a5cb-fd79-4677-aec4-52c04d799955"
      },
      "outputs": [],
      "source": [
        "k_values = [i for i in range (1,31)]\n",
        "scores = []\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1316f301-cb46-483b-a51b-d51bd539818d",
      "metadata": {
        "id": "1316f301-cb46-483b-a51b-d51bd539818d"
      },
      "source": [
        "For each k, we do the following:\n",
        "\n",
        "We create an instance of StratifiedKFold and a KNN classifier with the current value of k. This classifier will be used for cross-validation.\n",
        "\n",
        "The cross_val_score function performs cross-validation, where the dataset is split into multiple \"folds\" for training and testing. It returns an array of scores, one for each fold. ***np.mean(score)*** calculates the mean of the cross-validation scores obtained from the different folds.\n",
        "\n",
        "The mean score represents the model's performance with the current k value. We then adds the mean score to the scores list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "7c81e9d3-4ad4-4196-bc9a-a452737b57ed",
      "metadata": {
        "id": "7c81e9d3-4ad4-4196-bc9a-a452737b57ed"
      },
      "outputs": [],
      "source": [
        "for k in k_values:\n",
        "    # Create a StratifiedKFold instance for stratified cross-validation\n",
        "    stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    score = cross_val_score(knn, X, y, cv=stratified_cv)\n",
        "    scores.append(np.mean(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4f8daba-c176-4271-9685-412e076635f2",
      "metadata": {
        "id": "a4f8daba-c176-4271-9685-412e076635f2"
      },
      "source": [
        "We use the sns.lineplot function from the Seaborn library to generate a line plot (self-explanatory).\n",
        "\n",
        "*x=k_values* specifies that the k values (the values tested during hyperparameter tuning) will be used as the x-axis values in the plot. *y=scores* represents the mean accuracy scores associated with each value of k, and these scores will be displayed on the y-axis. *marker='o'* specifies that data points on the line plot will be marked with circular markers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "990baf81-2f5d-44bf-bf2d-883a81cf3408",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "990baf81-2f5d-44bf-bf2d-883a81cf3408",
        "outputId": "d284c5d8-a6e1-48aa-a320-de50037276b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy Score')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.lineplot(x = k_values, y = scores, marker = 'o')\n",
        "plt.xlabel(\"K Values\")\n",
        "plt.ylabel(\"Accuracy Score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cdb9e35-a3b7-4fae-933a-3b4fe986fd15",
      "metadata": {
        "id": "8cdb9e35-a3b7-4fae-933a-3b4fe986fd15"
      },
      "source": [
        "By assessing the relationship between different values of k and the corresponding mean accuracy scores, We can identify the optimal value of k that maximizes the model's accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc2f7d3-3a7c-487f-8036-eeb198e15155",
      "metadata": {
        "id": "4cc2f7d3-3a7c-487f-8036-eeb198e15155"
      },
      "source": [
        "We use NumPy's *np.argmax(scores)* to return the index where the maximum mean accuracy score is located in the scores list, and *best_k* is assigned the value of k associated with the index.\n",
        "\n",
        "We then train with the newly obtained K values for maximum accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "4cc1249b-0656-4c9c-ae7e-79e52020e9dd",
      "metadata": {
        "id": "4cc1249b-0656-4c9c-ae7e-79e52020e9dd"
      },
      "outputs": [],
      "source": [
        "best_index = np.argmax(scores)\n",
        "best_k = k_values[best_index]\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "975017f3-8d99-4207-aa80-febd5f8ab708",
      "metadata": {
        "id": "975017f3-8d99-4207-aa80-febd5f8ab708"
      },
      "source": [
        "Calculate accuracy of the model with the new K values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "d4d9ace3-671f-49b6-9fa8-6d660396bba8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4d9ace3-671f-49b6-9fa8-6d660396bba8",
        "outputId": "d6c765de-f229-4ab0-ff79-4eb3c47b9631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 82.52 %\n",
            "Precision: 0.8563..\n",
            "Recall: 0.7760..\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# Formatting output\n",
        "accuracy_percentage = round(accuracy * 100, 3)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_percentage, \"%\")\n",
        "print(\"Precision: {:.4f}..\".format(precision))\n",
        "print(\"Recall: {:.4f}..\".format(recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0ab213c-48e5-412a-926d-4b85502e67a0",
      "metadata": {
        "id": "a0ab213c-48e5-412a-926d-4b85502e67a0"
      },
      "source": [
        "#### Let's clarify these results...\n",
        "\n",
        "**Accuracy:** Accuracy measures the overall correctness of the model by calculating the ratio of correctly predicted instances to the total number of instances.\n",
        "\n",
        "- (Number of Correct Predictions) / (Total Number of Predictions)\n",
        "\n",
        "**Precision:** Precision is a measure of how many of the predicted positive instances were actually positive. High precision means that when the model predicts a positive class, it's more likely to be correct.\n",
        "\n",
        "- (True Positives) / (True Positives + False Positives)\n",
        "\n",
        "**Recall (Sensitivity or True Positive Rate):** Recall measures how many of the actual positive instances were correctly predicted as positive. High recall means the model is good at finding positive instances, but it may produce more false positives.\n",
        "\n",
        "- (True Positives) / (True Positives + False Negatives)\n",
        "\n",
        "There's often a trade-off between precision and recall. We can adjust this trade-off by changing the model's threshold for classifying instances, such as the choice of **k**\n",
        "\n",
        "For example, choosing a small **k** usually leads to High Precision, whereas choosing a large **k** usually leads to High Recall. This is why we use cross-validation to find the **k** value that fits our model best"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f05cf099-6413-4b0e-9d04-3df5d0c31daf",
      "metadata": {
        "id": "f05cf099-6413-4b0e-9d04-3df5d0c31daf"
      },
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc25ff2c-1c3a-487d-9bab-8b5850244781",
      "metadata": {
        "id": "fc25ff2c-1c3a-487d-9bab-8b5850244781"
      },
      "source": [
        "My main issue with this project is my lack of programming knowledge, it was difficult for me to understand some of the concepts required for the predictor implementation. I collaborated with a classmate for this project, and I now have a better grasp at the concepts of kNN and classification problems.\n",
        "\n",
        "In the case of using Machine Learning, specifically kNN, it is significantly useful for image and object recognition. Using it to identify and recognize faces, objects like flowers, floors, products, and the like. kNN can be applied to many labelling or classification problems and get results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "77c73452-4ecd-4e31-80cc-02fe5d0d327f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "77c73452-4ecd-4e31-80cc-02fe5d0d327f",
        "outputId": "7f763678-0432-4b42-b6b4-5024143eb2fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/gdo_rezsoc10_KNN.ipynb to html\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/jupyter-nbconvert\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jupyter_core/application.py\", line 280, in launch_instance\n",
            "    super().launch_instance(argv=argv, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/nbconvertapp.py\", line 423, in start\n",
            "    self.convert_notebooks()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/nbconvertapp.py\", line 597, in convert_notebooks\n",
            "    self.convert_single_notebook(notebook_filename)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/nbconvertapp.py\", line 560, in convert_single_notebook\n",
            "    output, resources = self.export_single_notebook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/nbconvertapp.py\", line 488, in export_single_notebook\n",
            "    output, resources = self.exporter.from_filename(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/exporter.py\", line 189, in from_filename\n",
            "    return self.from_file(f, resources=resources, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/exporter.py\", line 206, in from_file\n",
            "    return self.from_notebook_node(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/html.py\", line 223, in from_notebook_node\n",
            "    return super().from_notebook_node(nb, resources, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/templateexporter.py\", line 413, in from_notebook_node\n",
            "    output = self.template.render(nb=nb_copy, resources=resources)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jinja2/environment.py\", line 1301, in render\n",
            "    self.environment.handle_exception()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jinja2/environment.py\", line 936, in handle_exception\n",
            "    raise rewrite_traceback_stack(source=source)\n",
            "  File \"/usr/local/share/jupyter/nbconvert/templates/lab/index.html.j2\", line 3, in top-level template code\n",
            "    {% from 'jupyter_widgets.html.j2' import jupyter_widgets %}\n",
            "  File \"/usr/local/share/jupyter/nbconvert/templates/lab/base.html.j2\", line 2, in top-level template code\n",
            "    {% from 'celltags.j2' import celltags %}\n",
            "  File \"/usr/local/share/jupyter/nbconvert/templates/base/display_priority.j2\", line 1, in top-level template code\n",
            "    {%- extends 'base/null.j2' -%}\n",
            "  File \"/usr/local/share/jupyter/nbconvert/templates/base/null.j2\", line 26, in top-level template code\n",
            "    {%- block body -%}\n",
            "  File \"/usr/local/share/jupyter/nbconvert/templates/base/null.j2\", line 29, in block 'body'\n",
            "    {%- block body_loop -%}\n",
            "  File \"/usr/local/share/jupyter/nbconvert/templates/base/null.j2\", line 31, in block 'body_loop'\n",
            "    {%- block any_cell scoped -%}\n",
            "  File \"/usr/local/share/jupyter/nbconvert/templates/base/null.j2\", line 87, in block 'any_cell'\n",
            "    {%- block markdowncell scoped-%} {%- endblock markdowncell -%}\n",
            "  File \"/usr/local/share/jupyter/nbconvert/templates/lab/base.html.j2\", line 104, in block 'markdowncell'\n",
            "    {%- set html_value=cell.source  | markdown2html | strip_files_prefix -%}\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/html.py\", line 204, in markdown2html\n",
            "    return MarkdownWithMath(renderer=renderer).render(source)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 1001, in render\n",
            "    return self.parse(text)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 1004, in parse\n",
            "    out = self.output(preprocessing(text))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 1053, in output\n",
            "    out += self.tok()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 1063, in tok\n",
            "    return getattr(self, 'output_%s' % t)()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 1168, in output_paragraph\n",
            "    return self.renderer.paragraph(self.inline(self.token['text']))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 555, in __call__\n",
            "    return self.output(text, rules)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 585, in output\n",
            "    ret = manipulate(text)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 579, in manipulate\n",
            "    out = getattr(self, 'output_%s' % key)(m)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 641, in output_link\n",
            "    return self._process_link(m, m.group(3), m.group(4))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mistune.py\", line 661, in _process_link\n",
            "    return self.renderer.image(link, title, text)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/filters/markdown_mistune.py\", line 186, in image\n",
            "    raise InvalidNotebook(f\"missing attachment: {name}\")\n",
            "nbconvert.filters.markdown_mistune.InvalidNotebook: missing attachment: 624d3d0d-030a-43ed-89be-694176b45134.png\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-10f11d47b721>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jupyter nbconvert --to html /content/gdo_rezsoc10_KNN.ipynb\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'jupyter nbconvert --to html /content/gdo_rezsoc10_KNN.ipynb\n' returned non-zero exit status 1."
          ]
        }
      ],
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/gdo_rezsoc10_KNN.ipynb"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}